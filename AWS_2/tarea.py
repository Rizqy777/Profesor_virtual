import boto3
import time
import os
import json
from dotenv import load_dotenv

# Cargar variables de entorno desde .env
load_dotenv()


# ==================== GESTOR DE CONFIGURACIÃ“N ====================

class ConfigManager:
    """
    Clase para gestionar la configuraciÃ³n persistente entre ejecuciones.
    Guarda y carga los IDs de recursos en un archivo JSON.
    """
    
    CONFIG_FILE = "aws_config.json"
    
    # ConfiguraciÃ³n por defecto
    DEFAULT_CONFIG = {
        "vpc_id": None,
        "sg_id": None,
        "subnet_id": None,
        "instance_id": None,
        "efs_id": None,
        "volume_id": None,
        "key_pairs_name": None,
        "availability_zone": None,
        "mount_target_id": None,
        "s3_bucket": None
    }
    
    @staticmethod
    def cargar_config():
        """
        Carga la configuraciÃ³n desde el archivo JSON.
        Si no existe, crea uno nuevo con valores por defecto.
        """
        if os.path.exists(ConfigManager.CONFIG_FILE):
            try:
                with open(ConfigManager.CONFIG_FILE, 'r') as f:
                    config = json.load(f)
                    print(f"âœ“ ConfiguraciÃ³n cargada desde {ConfigManager.CONFIG_FILE}")
                    return config
            except Exception as e:
                print(f"âš  Error al cargar configuraciÃ³n: {str(e)}")
                return ConfigManager.DEFAULT_CONFIG.copy()
        else:
            print(f"â„¹ Archivo de configuraciÃ³n no encontrado, creando nuevo...")
            ConfigManager.guardar_config(ConfigManager.DEFAULT_CONFIG)
            return ConfigManager.DEFAULT_CONFIG.copy()
    
    @staticmethod
    def guardar_config(config):
        """
        Guarda la configuraciÃ³n en el archivo JSON.
        """
        try:
            with open(ConfigManager.CONFIG_FILE, 'w') as f:
                json.dump(config, f, indent=4)
            print(f"âœ“ ConfiguraciÃ³n guardada en {ConfigManager.CONFIG_FILE}")
        except Exception as e:
            print(f"âœ— Error al guardar configuraciÃ³n: {str(e)}")
    
    @staticmethod
    def actualizar(key, value):
        """
        Actualiza un valor especÃ­fico en la configuraciÃ³n.
        """
        config = ConfigManager.cargar_config()
        config[key] = value
        ConfigManager.guardar_config(config)
    
    @staticmethod
    def obtener(key, default=None):
        """
        Obtiene un valor especÃ­fico de la configuraciÃ³n.
        """
        config = ConfigManager.cargar_config()
        return config.get(key, default)
    
    @staticmethod
    def mostrar():
        """
        Muestra toda la configuraciÃ³n actual.
        """
        config = ConfigManager.cargar_config()
        print("\n" + "=" * 80)
        print("CONFIGURACIÃ“N ACTUAL (aws_config.json)")
        print("=" * 80)
        for key, value in config.items():
            if value:
                print(f"  {key}: {value}")
            else:
                print(f"  {key}: (no configurado)")
        print("=" * 80)
    
    @staticmethod
    def limpiar():
        """
        Limpia toda la configuraciÃ³n (la resetea a valores por defecto).
        """
        ConfigManager.guardar_config(ConfigManager.DEFAULT_CONFIG.copy())
        print("âœ“ ConfiguraciÃ³n limpiada")

class StorageManager:
    def __init__(self, region="us-east-1"):
        """
        Inicializa los clientes de AWS

        Args:
            region (str): RegiÃ³n de AWS donde crear los recursos (opcional, por defecto us-west-2)
        """
        self.region = region
        self.ec2_client = boto3.client("ec2", region_name=region)
        self.ec2_resource = boto3.resource("ec2", region_name=region)
        self.efs_client = boto3.client("efs", region_name=region)
        self.s3_client = boto3.client("s3", region_name=region)
        self.s3_resource = boto3.resource("s3", region_name=region)


    def crear_bucket_s3(self, bucket_name, acl="private", encryption=False):
        """
        CREAR BUCKET S3 (Amazon Simple Storage Service)

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre Ãºnico del bucket (debe ser Ãºnico globalmente)
                - Solo minÃºsculas, nÃºmeros, guiones
                - MÃ¡ximo 63 caracteres
                - No puede empezar ni terminar con nÃºmero

        ParÃ¡metros OPCIONALES:
            - acl (str): Control de acceso (private, public-read, public-read-write)
                - 'private': Solo el propietario puede acceder (RECOMENDADO)
                - 'public-read': Cualquiera puede leer
                - 'public-read-write': Cualquiera puede leer y escribir
            - encryption (bool): EncriptaciÃ³n en reposo (por defecto False)

        Almacena: Contenedor para almacenar objetos (archivos, datos, etc.)
        Casos de uso: Almacenar imÃ¡genes, backups, datos, logs, etc.
        """
        try:
            bucket_name = bucket_name.lower()
            print(f"\n[S3] Creando bucket: {bucket_name}...")
            print(f"  ACL: {acl}")
            print(f"  EncriptaciÃ³n: {encryption}")

            # ParÃ¡metros obligatorios
            params = {
                "Bucket": bucket_name,  # OBLIGATORIO: Nombre del bucket
                "ACL": acl,  # OPCIONAL: Control de acceso
            }

            # Crear bucket
            response = self.s3_client.create_bucket(
                Bucket=bucket_name,
                ACL=acl,
                CreateBucketConfiguration={"LocationConstraint": self.region}
                if self.region != "us-east-1"
                else {},
            )

            print(f"âœ“ Bucket creado: {bucket_name}")

            # Agregar etiquetas al bucket
            self.s3_client.put_bucket_tagging(
                Bucket=bucket_name,
                Tagging={"TagSet": [{"Key": "Nombre", "Value": bucket_name}]},
            )

            return bucket_name

        except Exception as e:
            if "BucketAlreadyOwnedByYou" in str(e):
                print(f"âš  Bucket '{bucket_name}' ya existe y te pertenece")
                return bucket_name
            elif "BucketAlreadyExists" in str(e):
                print(f"âœ— Error: Bucket '{bucket_name}' ya existe (pertenece a otro usuario)")
                return None
            print(f"âœ— Error al crear bucket: {str(e)}")
            return None


    def crear_carpeta_s3(self, bucket_name, folder_name):
        """
        CREAR CARPETA EN S3 (Simular carpeta usando prefijo)

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - folder_name (str): Nombre de la carpeta (ej: "datos", "backup/2024")

        NOTA: En S3, las "carpetas" no existen realmente, son prefijos de objetos
              Para crear una carpeta, subimos un objeto vacÃ­o con "/" al final

        Almacena: Prefijo para organizar objetos en el bucket
        """
        try:
            print(f"\n[S3] Creando carpeta: {bucket_name}/{folder_name}/")

            # Crear un objeto vacÃ­o para simular la carpeta
            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=f"{folder_name}/",  # OBLIGATORIO: Clave del objeto (carpeta)
                Body=b"",  # Objeto vacÃ­o
            )

            print(f"âœ“ Carpeta creada: {folder_name}/")
            return True

        except Exception as e:
            print(f"âœ— Error al crear carpeta: {str(e)}")
            return False

    def subir_archivo_s3(self, bucket_name, file_path, s3_key):
        """
        SUBIR ARCHIVO A S3

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - file_path (str): Ruta local del archivo
            - s3_key (str): Ruta en S3 (ej: "datos/archivo.csv")

        ParÃ¡metros OPCIONALES:
            - ExtraArgs: Metadatos, ACL, etc.
            - Callback: FunciÃ³n para monitorear progreso

        Almacena: Archivos en el bucket S3
        Casos de uso: Subir datos, imÃ¡genes, backups, etc.
        """
        try:
            print(f"\n[S3] Subiendo archivo a S3...")
            print(f"  Bucket: {bucket_name}")
            print(f"  Archivo local: {file_path}")
            print(f"  Ruta en S3: {s3_key}")

            # Verificar que el archivo existe
            if not os.path.exists(file_path):
                print(f"âœ— Error: Archivo no encontrado: {file_path}")
                return False

            # Subir archivo
            self.s3_client.upload_file(
                file_path,
                bucket_name,
                s3_key,
            )

            print(f"âœ“ Archivo subido exitosamente")
            return True

        except Exception as e:
            print(f"âœ— Error al subir archivo: {str(e)}")
            return False

    def subir_contenido_s3(self, bucket_name, contenido, s3_key, content_type="text/plain"):
        """
        SUBIR CONTENIDO DIRECTO A S3 (sin archivo local)

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - contenido (str o bytes): Contenido a subir
            - s3_key (str): Ruta en S3 (ej: "datos/archivo.csv")
            - content_type (str): Tipo MIME (text/plain, text/csv, application/json, etc.)

        Almacena: Contenido directo en S3 sin necesidad de archivo local
        Casos de uso: Crear archivos dinÃ¡micamente, datos generados
        """
        try:
            print(f"\n[S3] Subiendo contenido a S3...")
            print(f"  Bucket: {bucket_name}")
            print(f"  Ruta en S3: {s3_key}")
            print(f"  Tipo: {content_type}")

            # Convertir contenido a bytes si es string
            if isinstance(contenido, str):
                contenido = contenido.encode("utf-8")

            # Subir contenido
            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=s3_key,  # OBLIGATORIO: Ruta del objeto
                Body=contenido,  # OBLIGATORIO: Contenido
                ContentType=content_type,  # OPCIONAL: Tipo MIME
            )

            print(f"âœ“ Contenido subido exitosamente")
            return True

        except Exception as e:
            print(f"âœ— Error al subir contenido: {str(e)}")
            return False

    def subir_contenido_s3_con_storage_class(self, bucket_name, contenido, s3_key, 
                                         storage_class="STANDARD", content_type="text/plain"):
        """
        SUBIR CONTENIDO A S3 CON STORAGE CLASS ESPECÃFICA
        
        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - contenido (str o bytes): Contenido a subir
            - s3_key (str): Ruta en S3
            - storage_class (str): Clase de almacenamiento:
                - 'STANDARD': Acceso frecuente (defecto, costo normal)
                - 'STANDARD_IA': Acceso infrecuente (mÃ¡s barato, 30 dÃ­as mÃ­nimo)
                - 'INTELLIGENT_TIERING': AutomÃ¡tico segÃºn acceso (variable)
                - 'GLACIER': Archivo a largo plazo (muy barato, recuperaciÃ³n en horas)
                - 'DEEP_ARCHIVE': Compliance/Backup (baratÃ­simo, recuperaciÃ³n en 12+ horas)
                - 'ONEZONE_IA': Una sola zona (mÃ¡s barato que STANDARD_IA)
        
        Almacena: Contenido con clase de almacenamiento especÃ­fica
        Casos de uso: Optimizar costos segÃºn patrÃ³n de acceso
        """
        try:
            print(f"\n[S3] Subiendo contenido con Storage Class: {storage_class}...")
            print(f"  Bucket: {bucket_name}")
            print(f"  Ruta: {s3_key}")
            print(f"  Storage Class: {storage_class}")
            
            if isinstance(contenido, str):
                contenido = contenido.encode("utf-8")
            
            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=s3_key,
                Body=contenido,
                ContentType=content_type,
                StorageClass=storage_class  # CLAVE: Define la clase de almacenamiento
            )
            
            print(f"âœ“ Contenido subido exitosamente con {storage_class}")
            return True
            
        except Exception as e:
            print(f"âœ— Error: {str(e)}")
            return False

    def subir_archivo_s3_con_storage_class(self, bucket_name, file_path, s3_key, 
                                        storage_class="STANDARD"):
        """
        SUBIR ARCHIVO A S3 CON STORAGE CLASS ESPECÃFICA
        
        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - file_path (str): Ruta local del archivo
            - s3_key (str): Ruta en S3
            - storage_class (str): Clase de almacenamiento (ver arriba)
        
        Casos de uso: Subir backups a Glacier, datos histÃ³ricos a Deep Archive
        """
        try:
            print(f"\n[S3] Subiendo archivo con Storage Class: {storage_class}...")
            print(f"  Archivo local: {file_path}")
            print(f"  Ruta en S3: {s3_key}")
            
            if not os.path.exists(file_path):
                print(f"âœ— Archivo no encontrado: {file_path}")
                return False
            
            # Usar ExtraArgs para especificar StorageClass
            self.s3_client.upload_file(
                file_path,
                bucket_name,
                s3_key,
                ExtraArgs={'StorageClass': storage_class}
            )
            
            print(f"âœ“ Archivo subido con {storage_class}")
            return True
            
        except Exception as e:
            print(f"âœ— Error: {str(e)}")
            return False

    
    def listar_objetos_s3(self, bucket_name, prefix=""):
        """
        LISTAR OBJETOS EN S3

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket

        ParÃ¡metros OPCIONALES:
            - prefix (str): Filtrar por prefijo (ej: "datos/" para listar solo esa carpeta)

        Retorna: Lista de objetos en el bucket
        """
        try:
            print(f"\n[S3] Listando objetos en {bucket_name}...")

            response = self.s3_client.list_objects_v2(
                Bucket=bucket_name,
                Prefix=prefix,  # OPCIONAL: Filtrar por prefijo
            )

            if "Contents" not in response:
                print("  No hay objetos en el bucket")
                return []

            objetos = []
            for obj in response["Contents"]:
                tamaÃ±o = obj["Size"]
                fecha = obj["LastModified"]
                clave = obj["Key"]

                # No mostrar carpetas vacÃ­as (terminan en /)
                if not clave.endswith("/"):
                    print(f"  - {clave} ({tamaÃ±o} bytes, {fecha})")
                    objetos.append(clave)
                else:
                    print(f"  ðŸ“ {clave}")

            return objetos

        except Exception as e:
            print(f"âœ— Error al listar objetos: {str(e)}")
            return []
        
    def descargar_objeto_s3(self, bucket_name, s3_key, file_path=None):
        """
        DESCARGAR OBJETO DESDE S3

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - s3_key (str): Ruta del objeto en S3 (ej: "datos/archivo.csv")

        ParÃ¡metros OPCIONALES:
            - file_path (str): Ruta local donde guardar (por defecto usa el nombre del objeto)

        Retorna: Ruta donde se guardÃ³ el archivo
        """
        try:
            print(f"\n[S3] Descargando objeto desde S3...")
            print(f"  Bucket: {bucket_name}")
            print(f"  Objeto: {s3_key}")

            # Si no especifica ruta, usar el nombre del objeto
            if not file_path:
                file_path = os.path.basename(s3_key)

            # Crear carpetas si no existen
            os.makedirs(os.path.dirname(file_path) or ".", exist_ok=True)

            # Descargar archivo
            self.s3_client.download_file(bucket_name, s3_key, file_path)

            print(f"âœ“ Archivo descargado: {file_path}")
            return file_path

        except Exception as e:
            print(f"âœ— Error al descargar objeto: {str(e)}")
            return None

    def obtener_contenido_s3(self, bucket_name, s3_key):
        """
        OBTENER CONTENIDO DE UN OBJETO S3 (sin descargar archivo)

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - s3_key (str): Ruta del objeto (ej: "datos/archivo.csv")

        Retorna: Contenido del objeto como bytes
        """
        try:
            print(f"\n[S3] Obteniendo contenido desde S3...")
            print(f"  Bucket: {bucket_name}")
            print(f"  Objeto: {s3_key}")

            response = self.s3_client.get_object(
                Bucket=bucket_name,
                Key=s3_key,  # OBLIGATORIO: Clave del objeto
            )

            # Leer contenido
            contenido = response["Body"].read()

            print(f"âœ“ Contenido obtenido ({len(contenido)} bytes)")
            return contenido

        except Exception as e:
            print(f"âœ— Error al obtener contenido: {str(e)}")
            return None

    def obtener_contenido_s3_como_texto(self, bucket_name, s3_key):
        """
        OBTENER CONTENIDO DE UN OBJETO S3 COMO TEXTO

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - s3_key (str): Ruta del objeto (ej: "datos/archivo.csv")

        Retorna: Contenido como string
        """
        try:
            contenido_bytes = self.obtener_contenido_s3(bucket_name, s3_key)
            if contenido_bytes:
                return contenido_bytes.decode("utf-8")
            return None
        except Exception as e:
            print(f"âœ— Error al decodificar contenido: {str(e)}")
            return None

    def eliminar_objeto_s3(self, bucket_name, s3_key):
        """
        ELIMINAR OBJETO DE S3

        ParÃ¡metros OBLIGATORIOS:
            - bucket_name (str): Nombre del bucket
            - s3_key (str): Ruta del objeto a eliminar

        ADVERTENCIA: Esta acciÃ³n es irreversible
        """
        try:
            print(f"\n[S3] Eliminando objeto: {s3_key}")

            self.s3_client.delete_object(
                Bucket=bucket_name,
                Key=s3_key,  # OBLIGATORIO: Clave del objeto
            )

            print(f"âœ“ Objeto eliminado")
            return True

        except Exception as e:
            print(f"âœ— Error al eliminar objeto: {str(e)}")
            return False

    def eliminar_bucket_s3(self, bucket_name):
        """
        ELIMINAR BUCKET S3 (vacÃ­o)

        ParÃ¡metro OBLIGATORIO:
            - bucket_name (str): Nombre del bucket

        NOTA: El bucket DEBE estar vacÃ­o para poder eliminarlo
        ADVERTENCIA: Esta acciÃ³n es irreversible
        """
        try:
            print(f"\n[S3] Eliminando bucket: {bucket_name}")

            # Primero, eliminar todos los objetos
            print(f"  Limpiando objetos...")
            objetos = self.listar_objetos_s3(bucket_name)
            for obj in objetos:
                self.eliminar_objeto_s3(bucket_name, obj)

            # Eliminar el bucket
            self.s3_client.delete_bucket(Bucket=bucket_name)

            print(f"âœ“ Bucket eliminado")
            return True

        except Exception as e:
            print(f"âœ— Error al eliminar bucket: {str(e)}")
            return False
            
    # ==================== VPC/NETWORK MANAGEMENT ====================

    def obtener_vpc_predeterminada(self):
        """
        Obtiene la VPC por defecto de la regiÃ³n
        """
        try:
            response = self.ec2_client.describe_vpcs(
                Filters=[{"Name": "isDefault", "Values": ["true"]}]
            )
            if response["Vpcs"]:
                vpc_id = response["Vpcs"][0]["VpcId"]
                print(f"[VPC] VPC por defecto encontrada: {vpc_id}")
                return vpc_id
            else:
                print("[VPC] No se encontrÃ³ VPC por defecto")
                return None
        except Exception as e:
            print(f"âœ— Error al obtener VPC: {str(e)}")
            return None

    def obtener_subnet_predeterminada(self, vpc_id=None):
        """
        Obtiene una subred de la VPC (por defecto usa la VPC por defecto)
        Las subredes YA EXISTEN en tu VPC, no necesitan crearse
        """
        try:
            filters = []
            if vpc_id:
                filters.append({"Name": "vpc-id", "Values": [vpc_id]})

            response = self.ec2_client.describe_subnets(Filters=filters)
            if response["Subnets"]:
                subnet_id = response["Subnets"][0]["SubnetId"]
                availability_zone = response["Subnets"][0]["AvailabilityZone"]
                print(f"[SUBNET] Subred encontrada: {subnet_id} ({availability_zone})")
                return subnet_id, availability_zone
            else:
                print("[SUBNET] No se encontraron subredes")
                return None, None
        except Exception as e:
            print(f"âœ— Error al obtener subred: {str(e)}")
            return None, None

    def crear_security_group(self, sg_name, sg_description, vpc_id=None):
        """
        CREAR SECURITY GROUP NUEVO

        ParÃ¡metros OBLIGATORIOS:
            - sg_name (str): Nombre del security group
            - sg_description (str): DescripciÃ³n del SG

        ParÃ¡metros OPCIONALES:
            - vpc_id (str): ID de la VPC (por defecto crea en VPC por defecto)

        Retorna: ID del security group creado
        """
        try:
            print(f"\n[SG] Creando Security Group: {sg_name}...")

            # Si no especifica VPC, usa la por defecto
            if not vpc_id:
                vpc_id = self.obtener_vpc_predeterminada()
                if not vpc_id:
                    print("âœ— No se pudo obtener VPC por defecto")
                    return None

            params = {
                "GroupName": sg_name,
                "Description": sg_description,
                "VpcId": vpc_id,
            }

            response = self.ec2_client.create_security_group(**params)
            sg_id = response["GroupId"]

            print(f"âœ“ Security Group creado: {sg_id}")

            return sg_id

        except Exception as e:
            if "InvalidGroup.Duplicate" in str(e):
                print(f"âš  Security Group '{sg_name}' ya existe")
                # Obtener su ID
                response = self.ec2_client.describe_security_groups(
                    Filters=[{"Name": "group-name", "Values": [sg_name]}]
                )
                if response["SecurityGroups"]:
                    return response["SecurityGroups"][0]["GroupId"]
            print(f"âœ— Error al crear Security Group: {str(e)}")
            return None

    def agregar_regla_ingress_sg(
        self, sg_id, protocol, from_port, to_port, cidr="0.0.0.0/0"
    ):
        """
        AGREGAR REGLA INGRESS (ENTRADA) AL SECURITY GROUP

        ParÃ¡metros OBLIGATORIOS:
            - sg_id (str): ID del security group
            - protocol (str): Protocolo ('tcp', 'udp', 'icmp', '-1' para todos)
            - from_port (int): Puerto inicial
            - to_port (int): Puerto final
            - cidr (str): CIDR que puede acceder (por defecto 0.0.0.0/0 = todos)

        Ejemplos:
            - SSH: protocol='tcp', from_port=22, to_port=22
            - HTTP: protocol='tcp', from_port=80, to_port=80
            - HTTPS: protocol='tcp', from_port=443, to_port=443
            - Todos: protocol='-1', from_port=-1, to_port=-1
        """
        try:
            print(
                f"\n[SG] Agregando regla INGRESS: {protocol}:{from_port}-{to_port} desde {cidr}"
            )

            self.ec2_client.authorize_security_group_ingress(
                GroupId=sg_id,
                IpPermissions=[
                    {
                        "IpProtocol": protocol,
                        "FromPort": from_port,
                        "ToPort": to_port,
                        "IpRanges": [
                            {"CidrIp": cidr, "Description": "Acceso permitido"}
                        ],
                    }
                ],
            )

            print(f"âœ“ Regla ingress agregada")
            return True

        except Exception as e:
            if "InvalidPermission.Duplicate" in str(e):
                print(f"âš  Regla ya existe")
                return True
            print(f"âœ— Error al agregar regla: {str(e)}")
            return False

    def agregar_regla_egress_sg(
        self, sg_id, protocol, from_port, to_port, cidr="0.0.0.0/0"
    ):
        """
        AGREGAR REGLA EGRESS (SALIDA) AL SECURITY GROUP
        Similar a ingress pero para trÃ¡fico de salida
        """
        try:
            print(
                f"\n[SG] Agregando regla EGRESS: {protocol}:{from_port}-{to_port} hacia {cidr}"
            )

            self.ec2_client.authorize_security_group_egress(
                GroupId=sg_id,
                IpPermissions=[
                    {
                        "IpProtocol": protocol,
                        "FromPort": from_port,
                        "ToPort": to_port,
                        "IpRanges": [
                            {"CidrIp": cidr, "Description": "Acceso permitido"}
                        ],
                    }
                ],
            )

            print(f"âœ“ Regla egress agregada")
            return True

        except Exception as e:
            print(f"âœ— Error al agregar regla egress: {str(e)}")
            return False

    def crear_key_pair(self, key_name):
        """
        CREAR O VERIFICAR KEY PAIR PARA SSH

        ParÃ¡metro OBLIGATORIO:
            - key_name (str): Nombre de la key pair

        Retorna: Nombre de la key pair
        """
        try:
            # Verificar si existe
            response = self.ec2_client.describe_key_pairs(KeyNames=[key_name])
            print(f"âœ“ Key Pair ya existe: {key_name}")
            return key_name
        except:
            # Crear si no existe
            try:
                print(f"\n[KeyPair] Creando Key Pair: {key_name}...")
                response = self.ec2_client.create_key_pair(KeyName=key_name)
                print(f"âœ“ Key Pair creado: {key_name}")
                print(f"âš  Guarda el contenido abajo en un archivo .pem para SSH:")
                print(response["KeyMaterial"][:100] + "...")
                return key_name
            except Exception as e:
                print(f"âœ— Error al crear Key Pair: {str(e)}")
                return None

    # ==================== EC2 MANAGEMENT ====================
    # Almacenamiento: Instancias de mÃ¡quinas virtuales completas en la nube
    # Caso de uso: Ejecutar servidores web, aplicaciones, bases de datos

    def crear_ec2(
        self,
        instance_name,
        ami_id="ami-0ecb62995f68bb549",
        instance_type="t2.micro",
        security_group_name="sg-076af812ec93aff17",
        key_name="clave_casa",
        user_data=None,
    ):
        """
        CREAR INSTANCIA EC2

        ParÃ¡metros OBLIGATORIOS:
            - ami_id (str): ID de la imagen AMI (ej: ami-0ecb62995f68bb549 para Ubuntu en us-east-1)
            - instance_type (str): Tipo de instancia (t2.micro, t2.small, t3.medium, etc.)

        ParÃ¡metros OPCIONALES:
            - instance_name (str): Nombre para etiquetar la instancia
            - security_group_name (str): Grupo de seguridad a usar
            - key_name (str): Par de claves para SSH
            - user_data (str): Script bash a ejecutar al iniciar la instancia
            - MaxCount, MinCount: Cantidad de instancias (por defecto 1)

        Almacena: MÃ¡quina virtual con SO (Linux/Windows) lista para usar
        """
        try:
            print(f"\n[EC2] Creando instancia: {instance_name}...")

            # ParÃ¡metros obligatorios
            params = {
                "ImageId": ami_id,  # OBLIGATORIO: ID de la imagen
                "MinCount": 1,  # OBLIGATORIO: MÃ­nimo de instancias
                "MaxCount": 1,  # OBLIGATORIO: MÃ¡ximo de instancias
                "InstanceType": instance_type,  # OBLIGATORIO: Tipo de mÃ¡quina
                "SecurityGroupIds": security_group_name,  # OPCIONAL
                "KeyName": key_name,  # OPCIONAL
            }

            # ParÃ¡metros opcionales
            if security_group_name:
                params["SecurityGroupIds"] = [security_group_name]
            if key_name:
                params["KeyName"] = key_name
            if user_data:
                params["UserData"] = user_data  # Script a ejecutar al iniciar

            # Crear la instancia
            response = self.ec2_client.run_instances(**params)
            instance_id = response["Instances"][0]["InstanceId"]

            # Etiquetar la instancia (opcional pero Ãºtil)
            self.ec2_resource.create_tags(
                Resources=[instance_id], Tags=[{"Key": "Name", "Value": instance_name}]
            )

            print(f"âœ“ Instancia creada exitosamente: {instance_id}")
            print(f"  Estado: {response['Instances'][0]['State']['Name']}")

            return instance_id

        except Exception as e:
            print(f"âœ— Error al crear instancia EC2: {str(e)}")
            return None

    def ejecutar_ec2(self, instance_id):
        """
        EJECUTAR (INICIAR) INSTANCIA EC2

        ParÃ¡metro OBLIGATORIO:
            - instance_id (str): ID de la instancia a iniciar

        ParÃ¡metros OPCIONALES:
            - DryRun (bool): Simular la operaciÃ³n sin ejecutar
        """
        try:
            print(f"\n[EC2] Iniciando instancia: {instance_id}...")

            self.ec2_client.start_instances(InstanceIds=[instance_id])

            # Esperar a que inicie
            waiter = self.ec2_client.get_waiter("instance_running")
            waiter.wait(InstanceIds=[instance_id])

            print(f"âœ“ Instancia iniciada: {instance_id}")

        except Exception as e:
            print(f"âœ— Error al iniciar instancia: {str(e)}")

    def parar_ec2(self, instance_id):
        """
        PARAR INSTANCIA EC2

        ParÃ¡metro OBLIGATORIO:
            - instance_id (str): ID de la instancia a parar

        ParÃ¡metros OPCIONALES:
            - Force (bool): Forzar parada
            - Hibernate (bool): Hibernar en lugar de parar

        Nota: Los datos en EBS persisten cuando se para
        """
        try:
            print(f"\n[EC2] Parando instancia: {instance_id}...")

            self.ec2_client.stop_instances(InstanceIds=[instance_id])

            # Esperar a que se pare
            waiter = self.ec2_client.get_waiter("instance_stopped")
            waiter.wait(InstanceIds=[instance_id])

            print(f"âœ“ Instancia parada: {instance_id}")

        except Exception as e:
            print(f"âœ— Error al parar instancia: {str(e)}")

    def eliminar_ec2(self, instance_id):
        """
        ELIMINAR (TERMINAR) INSTANCIA EC2

        ParÃ¡metro OBLIGATORIO:
            - instance_id (str): ID de la instancia a eliminar

        ParÃ¡metros OPCIONALES:
            - Force (bool): Forzar terminaciÃ³n

        ADVERTENCIA: Esta acciÃ³n es irreversible. Los volÃºmenes EBS
                     con DeleteOnTermination=True tambiÃ©n se eliminarÃ¡n
        """
        try:
            print(f"\n[EC2] Eliminando instancia: {instance_id}...")

            self.ec2_client.terminate_instances(InstanceIds=[instance_id])

            # Esperar a que se termine
            waiter = self.ec2_client.get_waiter("instance_terminated")
            waiter.wait(InstanceIds=[instance_id])

            print(f"âœ“ Instancia eliminada: {instance_id}")

        except Exception as e:
            print(f"âœ— Error al eliminar instancia: {str(e)}")

    def obtener_estado_ec2(self, instance_id):
        """
        Obtener estado actual de una instancia EC2
        """
        try:
            response = self.ec2_client.describe_instances(InstanceIds=[instance_id])
            state = response["Reservations"][0]["Instances"][0]["State"]["Name"]
            print(f"[EC2] Estado de {instance_id}: {state}")
            return state
        except Exception as e:
            print(f"âœ— Error al obtener estado: {str(e)}")
            return None

    # ==================== EBS MANAGEMENT ====================
    # Almacenamiento: Almacenamiento en bloque persistente y de alto rendimiento
    # Caso de uso: Discos duros virtuales para bases de datos, archivos crÃ­ticos

    def crear_ebs(
        self, volume_name, size=20, availability_zone="us-east-1c", volume_type="gp3"
    ):
        """
        CREAR VOLUMEN EBS (Elastic Block Store)

        ParÃ¡metros OBLIGATORIOS:
            - Size (int): TamaÃ±o en GB (1-16384)
            - AvailabilityZone (str): Zona de disponibilidad (ej: us-west-2a)

        ParÃ¡metros OPCIONALES:
            - volume_name (str): Nombre para etiquetar el volumen
            - VolumeType (str): Tipo de volumen (gp2, gp3, io1, io2, st1, sc1)
                - gp3: PropÃ³sito general, mejor relaciÃ³n precio/rendimiento
                - io1/io2: IOPS provisionadas, muy alto rendimiento
                - st1: Optimizado para rendimiento
                - sc1: Optimizado para cold storage
            - Encrypted (bool): EncriptaciÃ³n (por defecto False)
            - Iops (int): IOPS provisionadas (solo para io1, io2, gp3)
            - Throughput (int): Rendimiento en MB/s (solo para gp3)
            - TagSpecifications: Etiquetas

        Almacena: Volumen de almacenamiento en bloque persistente
        Nota: DEBE estar en la MISMA zona de disponibilidad que el EC2
        """
        try:
            # Obtener zona de disponibilidad por defecto si no se proporciona
            if not availability_zone:
                response = self.ec2_client.describe_availability_zones()
                availability_zone = response["AvailabilityZones"][0]["ZoneName"]

            print(f"\n[EBS] Creando volumen EBS: {volume_name}...")
            print(f"  TamaÃ±o: {size} GB")
            print(f"  Tipo: {volume_type}")
            print(f"  Zona: {availability_zone}")

            # ParÃ¡metros obligatorios
            params = {
                "Size": size,  # OBLIGATORIO: TamaÃ±o en GB
                "AvailabilityZone": availability_zone,  # OBLIGATORIO: Zona
                "VolumeType": volume_type,  # OBLIGATORIO: Tipo de volumen
            }

            # ParÃ¡metros opcionales segÃºn tipo
            if volume_type in ["gp3", "io1", "io2"]:
                params["Iops"] = 3000  # IOPS mÃ­nimas para gp3
            if volume_type == "gp3":
                params["Throughput"] = 125  # Rendimiento en MB/s

            params["Encrypted"] = False  # Opcional: activar encriptaciÃ³n

            response = self.ec2_client.create_volume(**params)
            volume_id = response["VolumeId"]

            # Etiquetar el volumen
            self.ec2_resource.create_tags(
                Resources=[volume_id], Tags=[{"Key": "Name", "Value": volume_name}]
            )

            print(f"âœ“ Volumen EBS creado: {volume_id}")

            return volume_id

        except Exception as e:
            print(f"âœ— Error al crear volumen EBS: {str(e)}")
            return None

    def asociar_ebs_a_ec2(self, volume_id, instance_id, device="/dev/sdf"):
        """
        ASOCIAR VOLUMEN EBS A INSTANCIA EC2

        ParÃ¡metros OBLIGATORIOS:
            - volume_id (str): ID del volumen EBS
            - instance_id (str): ID de la instancia EC2
            - device (str): Nombre del dispositivo (ej: /dev/sdf, /dev/sdg)

        ParÃ¡metros OPCIONALES:
            - DeleteOnTermination (bool): Eliminar volumen al terminar EC2

        Nota: La instancia DEBE estar en RUNNING o STOPPED
        """
        try:
            print(f"\n[EBS] Asociando volumen {volume_id} a instancia {instance_id}...")

            self.ec2_client.attach_volume(
                VolumeId=volume_id, InstanceId=instance_id, Device=device
            )

            # Esperar a que se asocie
            time.sleep(2)

            print(f"âœ“ Volumen asociado en dispositivo {device}")

            return True

        except Exception as e:
            print(f"âœ— Error al asociar volumen: {str(e)}")
            return False

    def generar_user_data_montaje_ebs(
        self, device="/dev/sdf", mount_point="/mnt/datos"
    ):
        """
        GENERAR SCRIPT USER_DATA PARA MONTAR EBS AUTOMÃTICAMENTE

        Este script se ejecuta automÃ¡ticamente cuando inicia la instancia EC2

        ParÃ¡metros:
            - device (str): Dispositivo EBS asociado (ej: /dev/sdf)
            - mount_point (str): Ruta donde montar el EBS

        Retorna: Script bash para montar el EBS
        """
        user_data_script = f"""#!/bin/bash
# Script de montaje automÃ¡tico de EBS

echo "Esperando a que el dispositivo {device} estÃ© disponible..."
sleep 10

# Verificar si el dispositivo existe
if [ ! -e {device} ]; then
    echo "Error: Dispositivo {device} no encontrado"
    exit 1
fi

echo "Dispositivo encontrado: {device}"

# Verificar si tiene particiones
if ! sudo fdisk -l {device} | grep -q "Units="; then
    echo "Inicializando y formateando dispositivo {device}..."
    
    # Crear particiÃ³n
    sudo parted {device} mklabel gpt
    sudo parted {device} mkpart primary ext4 1 100%
    
    # Esperar a que se cree la particiÃ³n
    sleep 5
    
    # Formatear
    sudo mkfs.ext4 {device}1
fi

# Crear punto de montaje
sudo mkdir -p {mount_point}

# Montar el volumen
sudo mount {device}1 {mount_point}

# Cambiar permisos
sudo chown ec2-user:ec2-user {mount_point}
chmod 755 {mount_point}

# Agregar a fstab para montaje automÃ¡tico en reinicios
if ! grep -q "{device}" /etc/fstab; then
    echo "{device}1 {mount_point} ext4 defaults,nofail 0 2" | sudo tee -a /etc/fstab
fi

echo "EBS montado en {mount_point}"
df -h {mount_point}
"""
        return user_data_script

    def agregar_archivo_ebs(self, instance_id, archivo_path, contenido):
        """
        AGREGAR ARCHIVO AL VOLUMEN EBS (via SSH)

        NOTA: Requiere SSH accesible y credenciales de clave privada
        Para simplificar la demostraciÃ³n, usaremos user_data en EC2

        ParÃ¡metros:
            - instance_id: ID de la instancia
            - archivo_path: Ruta donde crear el archivo
            - contenido: Contenido del archivo
        """
        print(f"\n[EBS] Para agregar archivos al EBS, usa SSH o configurar user_data")
        print(f"      Archivo que se guardarÃ­a: {archivo_path}")
        print(f"      Contenido: {contenido[:50]}...")

    # ==================== EFS MANAGEMENT ====================
    # Almacenamiento: Sistema de archivos elÃ¡stico y compartido
    # Caso de uso: Almacenamiento compartido entre mÃºltiples EC2, aplicaciones web

    def crear_efs(
        self,
        fs_name,
        performance_mode="generalPurpose",
        throughput_mode="bursting",
        encrypted=False,
    ):
        """
        CREAR EFS (Elastic File System)

        ParÃ¡metros OBLIGATORIOS:
            - Ninguno (todos tienen valores por defecto)

        ParÃ¡metros OPCIONALES:
            - fs_name (str): Nombre del sistema de archivos
            - PerformanceMode (str): Tipo de rendimiento
                - 'generalPurpose': Latencia baja, propÃ³sito general (RECOMENDADO)
                - 'maxIO': MÃ¡ximo rendimiento, mayor latencia
            - ThroughputMode (str): Modo de rendimiento
                - 'bursting': Rendimiento variable (por defecto, sin costo adicional)
                - 'provisioned': Rendimiento garantizado (costo adicional)
            - ProvisionedThroughputInMibps (int): Rendimiento si ThroughputMode=provisioned
            - Encrypted (bool): EncriptaciÃ³n en reposo (por defecto False)
            - KmsKeyId (str): Clave KMS para encriptaciÃ³n

        Almacena: Sistema de archivos NFS compartido entre mÃºltiples EC2
        Ventaja: SincronizaciÃ³n automÃ¡tica, escalable, persistente
        """
        try:
            print(f"\n[EFS] Creando EFS: {fs_name}...")

            # ParÃ¡metros obligatorios
            params = {
                "PerformanceMode": performance_mode,  # OBLIGATORIO
                "ThroughputMode": throughput_mode,  # OBLIGATORIO
                "Encrypted": encrypted,  # OPCIONAL: EncriptaciÃ³n
            }

            response = self.efs_client.create_file_system(**params)
            fs_id = response["FileSystemId"]

            # Etiquetar el EFS
            self.efs_client.create_tags(
                FileSystemId=fs_id, Tags=[{"Key": "Name", "Value": fs_name}]
            )

            print(f"âœ“ EFS creado: {fs_id}")
            print(f"  Performance Mode: {performance_mode}")
            print(f"  Throughput Mode: {throughput_mode}")

            return fs_id

        except Exception as e:
            print(f"âœ— Error al crear EFS: {str(e)}")
            return None

    def crear_mount_target(self, fs_id, subnet_id, security_group_ids=None):
        """
        CREAR MOUNT TARGET PARA EFS

        ParÃ¡metros OBLIGATORIOS:
            - fs_id (str): ID del sistema de archivos EFS
            - subnet_id (str): ID de la subred donde montar

        ParÃ¡metros OPCIONALES:
            - security_group_ids (list): IDs de grupos de seguridad

        NOTA: Necesitas una VPC y subred preexistente
        """
        try:
            print(f"\n[EFS] Creando Mount Target para EFS {fs_id}...")

            params = {
                "FileSystemId": fs_id,  # OBLIGATORIO
                "SubnetId": subnet_id,  # OBLIGATORIO
            }

            if security_group_ids:
                params["SecurityGroups"] = security_group_ids

            response = self.efs_client.create_mount_target(**params)
            mount_target_id = response["MountTargetId"]

            print(f"âœ“ Mount Target creado: {mount_target_id}")

            return mount_target_id

        except Exception as e:
            print(f"âœ— Error al crear Mount Target: {str(e)}")
            return None

    def listar_efs(self):
        """
        Listar todos los EFS disponibles
        """
        try:
            print(f"\n[EFS] Listando sistemas de archivos...")
            response = self.efs_client.describe_file_systems()

            if not response["FileSystems"]:
                print("  No hay EFS disponibles")
                return []

            for fs in response["FileSystems"]:
                print(
                    f"  - {fs['FileSystemId']}: {fs['Name']} ({fs['LifeCycleState']})"
                )

            return response["FileSystems"]

        except Exception as e:
            print(f"âœ— Error al listar EFS: {str(e)}")
            return []


# ==================== PROGRAMA Security_Group_SUBNET_KeyPair ====================

def main_security_group_subnet_keypairs():

    # Crear instancia
    manager = StorageManager(region="us-east-1")

    # ========== PASO 0: CREAR INFRAESTRUCTURA DE RED ==========
    print("\n\n>>> PASO 0: CREAR SECURITY GROUP <<<")
    vpc_id = manager.obtener_vpc_predeterminada()

    sg_id = manager.crear_security_group(
        sg_name="almacenamiento-aws",
        sg_description="Security Group para EC2, EBS y EFS",
        vpc_id=vpc_id,
    )

    if sg_id:
        # Agregar reglas de acceso
        print("\n[SG] Agregando reglas de seguridad...")
        manager.agregar_regla_ingress_sg(sg_id, "tcp", 22, 22, "0.0.0.0/0")  # SSH
        manager.agregar_regla_ingress_sg(sg_id, "tcp", 80, 80, "0.0.0.0/0")  # HTTP
        manager.agregar_regla_ingress_sg(sg_id, "tcp", 443, 443, "0.0.0.0/0")  # HTTPS
        manager.agregar_regla_ingress_sg(
            sg_id, "-1", -1, -1, "0.0.0.0/0"
        )  # Todos (para NFS/EFS)
    else:
        print("âœ— No se pudo crear el security group")
        return

    # Obtener subred (YA EXISTE, no se crea)
    print("\n\n>>> PASO 0B: OBTENER SUBRED <<<")
    subnet_id, availability_zone = manager.obtener_subnet_predeterminada(vpc_id)

    if not subnet_id:
        print("âœ— No se encontrÃ³ subred disponible")
        return

    # ========== PASO 0C: CREAR/VERIFICAR KEY PAIR ==========
    print("\n\n>>> PASO 0C: CREAR/VERIFICAR KEY PAIR <<<")
    key_name = manager.crear_key_pair("clave_casa")

    if not key_name:
        print("âœ— No se pudo crear/verificar la key pair")
        return

    # Guardar en archivo de configuraciÃ³n
    ConfigManager.actualizar("sg_id", sg_id)
    ConfigManager.actualizar("subnet_id", subnet_id)
    ConfigManager.actualizar("key_pairs_name", key_name)
    ConfigManager.actualizar("availability_zone", availability_zone)
    
    print("\nâœ“ Infraestructura guardada en aws_config.json")

# ==================== PROGRAMA EC2_EFS_EBS ====================

def main_ec2_efs_ebs():
    
    print("=" * 80)
    print("GESTOR DE ALMACENAMIENTO AWS (EC2, EBS, EFS)")
    print("=" * 80)

    # Crear instancia
    manager = StorageManager(region="us-east-1")

    # Cargar configuraciÃ³n guardada
    key_name = ConfigManager.obtener("key_pairs_name")
    sg_id = ConfigManager.obtener("sg_id")
    subnet_id = ConfigManager.obtener("subnet_id")
    availability_zone = ConfigManager.obtener("availability_zone")
    
    if not all([key_name, sg_id, subnet_id]):
        print("âœ— Error: Debes ejecutar MAIN 1 primero para crear la infraestructura")
        return
    
    print(f"\n[CONFIG] Usando datos guardados:")
    print(f"  SG: {sg_id}")
    print(f"  Subnet: {subnet_id}")
    print(f"  Key: {key_name}")

    # # ========== PASO 1: CREAR Y GESTIONAR EC2 ==========
    print("\n\n>>> PASO 1: CREAR INSTANCIA EC2 <<<")

    # Generar script para montar el EBS automÃ¡ticamente
    user_data = manager.generar_user_data_montaje_ebs(
        device="/dev/sdf", mount_point="/mnt/datos"
    )

    instance_id = manager.crear_ec2(
        instance_name="mi-servidor-web",
        ami_id="ami-0ecb62995f68bb549",
        instance_type="t2.micro",
        key_name=key_name,
        security_group_name=sg_id,
        user_data=user_data,
    )

    if not instance_id:
        print("âœ— Error: No se pudo crear la instancia EC2")
        return

    if instance_id:
        manager.ec2_client.get_waiter("instance_running").wait(
            InstanceIds=[instance_id]
        )

    if instance_id:
        # Esperar a que la instancia estÃ© disponible
        time.sleep(5)

        print("\n>>> PASO 2: VERIFICAR ESTADO DE EC2 <<<")
        manager.obtener_estado_ec2(instance_id)

        print("\n>>> PASO 3: PARAR EC2 <<<")
        manager.parar_ec2(instance_id)

        time.sleep(3)

        print("\n>>> PASO 4: EJECUTAR EC2 <<<")
        manager.ejecutar_ec2(instance_id)

        time.sleep(3)

    ConfigManager.actualizar("instance_id", instance_id)

    # ========== PASO 5: CREAR Y ASOCIAR EBS ==========
    print("\n\n>>> PASO 5: CREAR VOLUMEN EBS <<<")

    volume_id = manager.crear_ebs(
        volume_name="mi-volumen-datos",
        size=20,
        volume_type="gp3",
        availability_zone=availability_zone,
    )

    if volume_id:
        time.sleep(3)

        print("\n>>> PASO 6: ASOCIAR EBS A EC2 <<<")
        manager.asociar_ebs_a_ec2(volume_id, instance_id, device="/dev/sdf")

        print("\n>>> PASO 7: AGREGAR ARCHIVO A EBS <<<")

    ConfigManager.actualizar("volume_id", volume_id)

    # ========== PASO 8: CREAR EFS ==========
    print("\n\n>>> PASO 8: CREAR EFS (SISTEMA DE ARCHIVOS COMPARTIDO) <<<")
    efs_id = manager.crear_efs(
        fs_name="mi-efs-compartido",
        performance_mode="generalPurpose",
        throughput_mode="bursting",
        encrypted=False,
    )

    if not efs_id:
        print("âœ— Error: No se pudo crear EFS")
        return

    ConfigManager.actualizar("efs_id", efs_id)

    while True:
        estado = manager.efs_client.describe_file_systems(FileSystemId=efs_id)[
            "FileSystems"
        ][0]["LifeCycleState"]
        if estado == "available":
            break
        print(f"EFS aÃºn en estado {estado}, esperando...")
        time.sleep(3)

    if efs_id:
        time.sleep(2)

        # ========== PASO 9: CREAR MOUNT TARGET PARA EFS ==========
        print("\n\n>>> PASO 9: CREAR MOUNT TARGET PARA EFS <<<")

        if subnet_id:
            mount_target_id = manager.crear_mount_target(
                fs_id=efs_id,
                subnet_id=subnet_id,
                security_group_ids=[sg_id],
            )
        else:
            print("No se pudo obtener el subnet_id, no se crearÃ¡ el Mount Target.")
            mount_target_id = None

        if mount_target_id:
            ConfigManager.actualizar("mount_target_id", mount_target_id)
            time.sleep(2)

            # ========== PASO 10: LISTAR EFS DISPONIBLES ===
            print("\n\n>>> PASO 10: LISTAR EFS DISPONIBLES <<<")
            manager.listar_efs()

    print("\nâœ“ EC2, EBS y EFS guardados en aws_config.json")


# ==================== PROGRAMA S3_STANDARD ====================

def main_s3_STANDARD():
    """
    MAIN 3: S3 - Crear bucket, carpetas y archivos CSV
    
    Pasos:
    1. Crear bucket S3 estÃ¡ndar
    2. Crear carpetas dentro del bucket
    3. Crear archivos CSV con datos
    4. Listar objetos
    5. Descargar/Obtener objetos
    """
    
    print("=" * 80)
    print("PARTE 3: S3 (SIMPLE STORAGE SERVICE)")
    print("=" * 80)
    
    # Crear instancia de manager
    manager = StorageManager(region="us-east-1")
    
    # PASO 1: Crear bucket S3
    print("\n\n>>> PASO 1: CREAR BUCKET S3 <<<")
    bucket_name = "mi-bucket-datos-" + str(int(time.time()))  # Nombre Ãºnico
    
    bucket_creado = manager.crear_bucket_s3(
        bucket_name=bucket_name,
        acl="private",
        encryption=False  # OPCIONAL: EncriptaciÃ³n
    )
    
    if not bucket_creado:
        print("âœ— Error: No se pudo crear el bucket")
        return
    
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    # PASO 2: Crear carpetas en S3
    print("\n\n>>> PASO 2: CREAR CARPETAS EN S3 <<<")
    
    carpetas = ["ventas", "clientes", "productos", "reportes"]
    
    for carpeta in carpetas:
        manager.crear_carpeta_s3(bucket_name, carpeta)
    
    # PASO 3: Crear archivos CSV y subirlos
    print("\n\n>>> PASO 3: CREAR Y SUBIR ARCHIVOS CSV <<<")
    
    # CSV 1: Datos de ventas
    print("\n[CSV] Creando CSV de VENTAS...")
    csv_ventas = """id,fecha,producto,cantidad,precio,total
1,2024-01-01,Laptop,5,1200.00,6000.00
2,2024-01-02,Mouse,50,25.00,1250.00
3,2024-01-03,Teclado,30,75.00,2250.00
4,2024-01-04,Monitor,10,300.00,3000.00
5,2024-01-05,Auriculares,25,80.00,2000.00
6,2024-01-06,Webcam,15,120.00,1800.00
7,2024-01-07,SSD,8,450.00,3600.00
8,2024-01-08,RAM,20,100.00,2000.00
9,2024-01-09,Procesador,5,550.00,2750.00
10,2024-01-10,Fuente,12,200.00,2400.00"""
    
    manager.subir_contenido_s3(
        bucket_name=bucket_name,
        contenido=csv_ventas,
        s3_key="ventas/ventas_enero_2024.csv",  # Ruta con carpeta
        content_type="text/csv"
    )
    
    # CSV 2: Datos de clientes
    print("\n[CSV] Creando CSV de CLIENTES...")
    csv_clientes = """id,nombre,email,telefono,ciudad,activo
101,Juan GarcÃ­a,juan@example.com,555-0001,Madrid,true
102,MarÃ­a LÃ³pez,maria@example.com,555-0002,Barcelona,true
103,Carlos RodrÃ­guez,carlos@example.com,555-0003,Valencia,false
104,Ana MartÃ­nez,ana@example.com,555-0004,Sevilla,true
105,Luis FernÃ¡ndez,luis@example.com,555-0005,Bilbao,true
106,Elena JimÃ©nez,elena@example.com,555-0006,Malaga,true
107,David PÃ©rez,david@example.com,555-0007,Murcia,false
108,Sofia GÃ³mez,sofia@example.com,555-0008,Palma,true
109,Miguel SÃ¡nchez,miguel@example.com,555-0009,Las Palmas,true
110,Isabel Ruiz,isabel@example.com,555-0010,Alicante,false"""
    
    manager.subir_contenido_s3(
        bucket_name=bucket_name,
        contenido=csv_clientes,
        s3_key="clientes/clientes_activos.csv",
        content_type="text/csv"
    )
    
    # CSV 3: Datos de productos
    print("\n[CSV] Creando CSV de PRODUCTOS...")
    csv_productos = """id,nombre,categoria,precio,stock,proveedor
1001,Laptop Dell XPS,Computadoras,1200.00,15,Dell Inc
1002,Mouse Logitech,PerifÃ©ricos,25.00,100,Logitech
1003,Teclado MecÃ¡nico,PerifÃ©ricos,75.00,45,Keychron
1004,Monitor LG 27,Pantallas,300.00,8,LG
1005,Auriculares Sony,Audio,80.00,60,Sony
1006,Webcam HD,Accesorios,120.00,25,Logitech
1007,SSD Samsung 1TB,Almacenamiento,450.00,20,Samsung
1008,RAM DDR4 16GB,Componentes,100.00,50,Corsair
1009,Procesador Intel,Componentes,550.00,12,Intel
1010,Fuente 750W,Componentes,200.00,18,EVGA"""
    
    manager.subir_contenido_s3(
        bucket_name=bucket_name,
        contenido=csv_productos,
        s3_key="productos/inventario.csv",
        content_type="text/csv"
    )
    
    # CSV 4: Reportes
    print("\n[CSV] Creando CSV de REPORTES...")
    csv_reportes = """mes,ingresos,gastos,ganancia,margen
Enero,15100.00,8500.00,6600.00,0.437
Febrero,18200.00,9100.00,9100.00,0.500
Marzo,21500.00,10200.00,11300.00,0.525
Abril,19800.00,9800.00,10000.00,0.505
Mayo,23100.00,11000.00,12100.00,0.524
Junio,25600.00,12000.00,13600.00,0.531"""
    
    manager.subir_contenido_s3(
        bucket_name=bucket_name,
        contenido=csv_reportes,
        s3_key="reportes/resumen_financiero.csv",
        content_type="text/csv"
    )
    
    # PASO 4: Listar objetos en el bucket
    print("\n\n>>> PASO 4: LISTAR TODOS LOS OBJETOS <<<")
    todos_los_objetos = manager.listar_objetos_s3(bucket_name)
    
    # PASO 5: Listar objetos por carpeta
    print("\n\n>>> PASO 5: LISTAR OBJETOS POR CARPETA <<<")
    
    print("\n[S3] Objetos en carpeta 'ventas':")
    manager.listar_objetos_s3(bucket_name, prefix="ventas/")
    
    print("\n[S3] Objetos en carpeta 'clientes':")
    manager.listar_objetos_s3(bucket_name, prefix="clientes/")
    
    # PASO 6: Obtener contenido de un objeto (sin descargar)
    print("\n\n>>> PASO 6: OBTENER CONTENIDO DE OBJETO (EN MEMORIA) <<<")
    
    print("\n[S3] Obteniendo contenido de 'ventas/ventas_enero_2024.csv'...")
    contenido_ventas = manager.obtener_contenido_s3_como_texto(
        bucket_name=bucket_name,
        s3_key="ventas/ventas_enero_2024.csv"
    )
    
    if contenido_ventas:
        print(f"\n[CONTENIDO] Primeras lÃ­neas del archivo:")
        lineas = contenido_ventas.split("\n")[:5]
        for linea in lineas:
            print(f"  {linea}")
        print(f"  ... ({len(contenido_ventas.split(chr(10)))} filas totales)")
    
    # PASO 7: Descargar objeto a archivo local
    print("\n\n>>> PASO 7: DESCARGAR OBJETO A ARCHIVO LOCAL <<<")
    
    archivo_descargado = manager.descargar_objeto_s3(
        bucket_name=bucket_name,
        s3_key="clientes/clientes_activos.csv",
        file_path="clientes_descargados.csv"
    )
    
    # PASO 8: Obtener informaciÃ³n de objetos especÃ­ficos
    print("\n\n>>> PASO 8: OBTENER INFORMACIÃ“N DE OBJETOS <<<")
    
    objetos_info = {
        "ventas/ventas_enero_2024.csv": "Datos de ventas de enero",
        "clientes/clientes_activos.csv": "Lista de clientes activos",
        "productos/inventario.csv": "Inventario de productos",
        "reportes/resumen_financiero.csv": "Resumen financiero del semestre"
    }
    
    for obj_key, descripcion in objetos_info.items():
        try:
            metadata = manager.s3_client.head_object(
                Bucket=bucket_name,
                Key=obj_key
            )
            tamaÃ±o = metadata["ContentLength"]
            print(f"\n[OBJETO] {obj_key}")
            print(f"  DescripciÃ³n: {descripcion}")
            print(f"  TamaÃ±o: {tamaÃ±o} bytes")
            print(f"  Ãšltima modificaciÃ³n: {metadata['LastModified']}")
        except Exception as e:
            print(f"Error: {str(e)}")
    
    # Guardar info del bucket en archivo de configuraciÃ³n
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    print("\n" + "=" * 80)
    print("âœ“ S3 completado exitosamente")
    print("=" * 80)
    print(f"\nInformaciÃ³n del bucket:")
    print(f"  Nombre: {bucket_name}")
    print(f"  RegiÃ³n: us-east-1")
    print(f"  Objetos creados: {len(todos_los_objetos)}")
    
# ==================== PROGRAMA S3_STANDARD_IA ====================

def main_s3_STANDARD_IA():
    """
    MAIN 3: S3 - Crear bucket, carpetas y archivos CSV
    
    Pasos:
    1. Crear bucket S3 estÃ¡ndar
    2. Crear carpetas dentro del bucket
    3. Crear archivos CSV con datos
    4. Listar objetos
    5. Descargar/Obtener objetos
    """
    
    print("=" * 80)
    print("PARTE 3: S3 (SIMPLE STORAGE SERVICE)")
    print("=" * 80)
    
    # Crear instancia de manager
    manager = StorageManager(region="us-east-1")
    
    # PASO 1: Crear bucket S3
    print("\n\n>>> PASO 1: CREAR BUCKET S3 <<<")
    bucket_name = "mi-bucket-datos-standard-ia" + str(int(time.time()))  # Nombre Ãºnico
    
    bucket_creado = manager.crear_bucket_s3(
        bucket_name=bucket_name,
        acl="private",
        encryption=False  # OPCIONAL: EncriptaciÃ³n
    )
    
    if not bucket_creado:
        print("âœ— Error: No se pudo crear el bucket")
        return
    
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    # PASO 2: Crear carpetas en S3
    print("\n\n>>> PASO 2: CREAR CARPETAS EN S3 <<<")
    
    carpetas = ["ventas", "clientes", "productos", "reportes"]
    
    for carpeta in carpetas:
        manager.crear_carpeta_s3(bucket_name, carpeta)
    
    # PASO 3: Crear archivos CSV y subirlos
    print("\n\n>>> PASO 3: CREAR Y SUBIR ARCHIVOS CSV <<<")
    
    # CSV 1: Datos de ventas
    print("\n[CSV] Creando CSV de VENTAS...")
    csv_ventas = """id,fecha,producto,cantidad,precio,total
1,2024-01-01,Laptop,5,1200.00,6000.00
2,2024-01-02,Mouse,50,25.00,1250.00
3,2024-01-03,Teclado,30,75.00,2250.00
4,2024-01-04,Monitor,10,300.00,3000.00
5,2024-01-05,Auriculares,25,80.00,2000.00
6,2024-01-06,Webcam,15,120.00,1800.00
7,2024-01-07,SSD,8,450.00,3600.00
8,2024-01-08,RAM,20,100.00,2000.00
9,2024-01-09,Procesador,5,550.00,2750.00
10,2024-01-10,Fuente,12,200.00,2400.00"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_ventas,
        s3_key="ventas/ventas_enero_2024.csv",  # Ruta con carpeta
        content_type="text/csv",
        storage_class="STANDARD_IA"
    )
    
    # CSV 2: Datos de clientes
    print("\n[CSV] Creando CSV de CLIENTES...")
    csv_clientes = """id,nombre,email,telefono,ciudad,activo
101,Juan GarcÃ­a,juan@example.com,555-0001,Madrid,true
102,MarÃ­a LÃ³pez,maria@example.com,555-0002,Barcelona,true
103,Carlos RodrÃ­guez,carlos@example.com,555-0003,Valencia,false
104,Ana MartÃ­nez,ana@example.com,555-0004,Sevilla,true
105,Luis FernÃ¡ndez,luis@example.com,555-0005,Bilbao,true
106,Elena JimÃ©nez,elena@example.com,555-0006,Malaga,true
107,David PÃ©rez,david@example.com,555-0007,Murcia,false
108,Sofia GÃ³mez,sofia@example.com,555-0008,Palma,true
109,Miguel SÃ¡nchez,miguel@example.com,555-0009,Las Palmas,true
110,Isabel Ruiz,isabel@example.com,555-0010,Alicante,false"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_clientes,
        s3_key="clientes/clientes_activos.csv",
        content_type="text/csv",
        storage_class="STANDARD_IA"
    )
    
    # CSV 3: Datos de productos
    print("\n[CSV] Creando CSV de PRODUCTOS...")
    csv_productos = """id,nombre,categoria,precio,stock,proveedor
1001,Laptop Dell XPS,Computadoras,1200.00,15,Dell Inc
1002,Mouse Logitech,PerifÃ©ricos,25.00,100,Logitech
1003,Teclado MecÃ¡nico,PerifÃ©ricos,75.00,45,Keychron
1004,Monitor LG 27,Pantallas,300.00,8,LG
1005,Auriculares Sony,Audio,80.00,60,Sony
1006,Webcam HD,Accesorios,120.00,25,Logitech
1007,SSD Samsung 1TB,Almacenamiento,450.00,20,Samsung
1008,RAM DDR4 16GB,Componentes,100.00,50,Corsair
1009,Procesador Intel,Componentes,550.00,12,Intel
1010,Fuente 750W,Componentes,200.00,18,EVGA"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_productos,
        s3_key="productos/inventario.csv",
        content_type="text/csv",
        storage_class="STANDARD_IA"
    )
    
    # CSV 4: Reportes
    print("\n[CSV] Creando CSV de REPORTES...")
    csv_reportes = """mes,ingresos,gastos,ganancia,margen
Enero,15100.00,8500.00,6600.00,0.437
Febrero,18200.00,9100.00,9100.00,0.500
Marzo,21500.00,10200.00,11300.00,0.525
Abril,19800.00,9800.00,10000.00,0.505
Mayo,23100.00,11000.00,12100.00,0.524
Junio,25600.00,12000.00,13600.00,0.531"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_reportes,
        s3_key="reportes/resumen_financiero.csv",
        content_type="text/csv",
        storage_class="STANDARD_IA"
    )
    
    # PASO 4: Listar objetos en el bucket
    print("\n\n>>> PASO 4: LISTAR TODOS LOS OBJETOS <<<")
    todos_los_objetos = manager.listar_objetos_s3(bucket_name)
    
    # PASO 5: Listar objetos por carpeta
    print("\n\n>>> PASO 5: LISTAR OBJETOS POR CARPETA <<<")
    
    print("\n[S3] Objetos en carpeta 'ventas':")
    manager.listar_objetos_s3(bucket_name, prefix="ventas/")
    
    print("\n[S3] Objetos en carpeta 'clientes':")
    manager.listar_objetos_s3(bucket_name, prefix="clientes/")
    
    # PASO 6: Obtener contenido de un objeto (sin descargar)
    print("\n\n>>> PASO 6: OBTENER CONTENIDO DE OBJETO (EN MEMORIA) <<<")
    
    print("\n[S3] Obteniendo contenido de 'ventas/ventas_enero_2024.csv'...")
    contenido_ventas = manager.obtener_contenido_s3_como_texto(
        bucket_name=bucket_name,
        s3_key="ventas/ventas_enero_2024.csv"
    )
    
    if contenido_ventas:
        print(f"\n[CONTENIDO] Primeras lÃ­neas del archivo:")
        lineas = contenido_ventas.split("\n")[:5]
        for linea in lineas:
            print(f"  {linea}")
        print(f"  ... ({len(contenido_ventas.split(chr(10)))} filas totales)")
    
    # PASO 7: Descargar objeto a archivo local
    print("\n\n>>> PASO 7: DESCARGAR OBJETO A ARCHIVO LOCAL <<<")
    
    archivo_descargado = manager.descargar_objeto_s3(
        bucket_name=bucket_name,
        s3_key="clientes/clientes_activos.csv",
        file_path="clientes_descargados.csv"
    )
    
    # PASO 8: Obtener informaciÃ³n de objetos especÃ­ficos
    print("\n\n>>> PASO 8: OBTENER INFORMACIÃ“N DE OBJETOS <<<")
    
    objetos_info = {
        "ventas/ventas_enero_2024.csv": "Datos de ventas de enero",
        "clientes/clientes_activos.csv": "Lista de clientes activos",
        "productos/inventario.csv": "Inventario de productos",
        "reportes/resumen_financiero.csv": "Resumen financiero del semestre"
    }
    
    for obj_key, descripcion in objetos_info.items():
        try:
            metadata = manager.s3_client.head_object(
                Bucket=bucket_name,
                Key=obj_key
            )
            tamaÃ±o = metadata["ContentLength"]
            print(f"\n[OBJETO] {obj_key}")
            print(f"  DescripciÃ³n: {descripcion}")
            print(f"  TamaÃ±o: {tamaÃ±o} bytes")
            print(f"  Ãšltima modificaciÃ³n: {metadata['LastModified']}")
        except Exception as e:
            print(f"Error: {str(e)}")
    
    # Guardar info del bucket en archivo de configuraciÃ³n
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    print("\n" + "=" * 80)
    print("âœ“ S3 completado exitosamente")
    print("=" * 80)
    print(f"\nInformaciÃ³n del bucket:")
    print(f"  Nombre: {bucket_name}")
    print(f"  RegiÃ³n: us-east-1")
    print(f"  Objetos creados: {len(todos_los_objetos)}")

# ==================== PROGRAMA S3_INTELLIGENT_TIERING ====================    

def main_s3_INTELLIGENT_TIERING():
    """
    MAIN 3: S3 - Crear bucket, carpetas y archivos CSV
    
    Pasos:
    1. Crear bucket S3 estÃ¡ndar
    2. Crear carpetas dentro del bucket
    3. Crear archivos CSV con datos
    4. Listar objetos
    5. Descargar/Obtener objetos
    """
    
    print("=" * 80)
    print("PARTE 3: S3 (SIMPLE STORAGE SERVICE)")
    print("=" * 80)
    
    # Crear instancia de manager
    manager = StorageManager(region="us-east-1")
    
    # PASO 1: Crear bucket S3
    print("\n\n>>> PASO 1: CREAR BUCKET S3 <<<")
    bucket_name = "mi-bucket-datos-intelligent-tiering" + str(int(time.time()))  # Nombre Ãºnico
    
    bucket_creado = manager.crear_bucket_s3(
        bucket_name=bucket_name,
        acl="private",
        encryption=False  # OPCIONAL: EncriptaciÃ³n
    )
    
    if not bucket_creado:
        print("âœ— Error: No se pudo crear el bucket")
        return
    
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    # PASO 2: Crear carpetas en S3
    print("\n\n>>> PASO 2: CREAR CARPETAS EN S3 <<<")
    
    carpetas = ["ventas", "clientes", "productos", "reportes"]
    
    for carpeta in carpetas:
        manager.crear_carpeta_s3(bucket_name, carpeta)
    
    # PASO 3: Crear archivos CSV y subirlos
    print("\n\n>>> PASO 3: CREAR Y SUBIR ARCHIVOS CSV <<<")
    
    # CSV 1: Datos de ventas
    print("\n[CSV] Creando CSV de VENTAS...")
    csv_ventas = """id,fecha,producto,cantidad,precio,total
1,2024-01-01,Laptop,5,1200.00,6000.00
2,2024-01-02,Mouse,50,25.00,1250.00
3,2024-01-03,Teclado,30,75.00,2250.00
4,2024-01-04,Monitor,10,300.00,3000.00
5,2024-01-05,Auriculares,25,80.00,2000.00
6,2024-01-06,Webcam,15,120.00,1800.00
7,2024-01-07,SSD,8,450.00,3600.00
8,2024-01-08,RAM,20,100.00,2000.00
9,2024-01-09,Procesador,5,550.00,2750.00
10,2024-01-10,Fuente,12,200.00,2400.00"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_ventas,
        s3_key="ventas/ventas_enero_2024.csv",  # Ruta con carpeta
        content_type="text/csv",
        storage_class="INTELLIGENT_TIERING"
    )
    
    # CSV 2: Datos de clientes
    print("\n[CSV] Creando CSV de CLIENTES...")
    csv_clientes = """id,nombre,email,telefono,ciudad,activo
101,Juan GarcÃ­a,juan@example.com,555-0001,Madrid,true
102,MarÃ­a LÃ³pez,maria@example.com,555-0002,Barcelona,true
103,Carlos RodrÃ­guez,carlos@example.com,555-0003,Valencia,false
104,Ana MartÃ­nez,ana@example.com,555-0004,Sevilla,true
105,Luis FernÃ¡ndez,luis@example.com,555-0005,Bilbao,true
106,Elena JimÃ©nez,elena@example.com,555-0006,Malaga,true
107,David PÃ©rez,david@example.com,555-0007,Murcia,false
108,Sofia GÃ³mez,sofia@example.com,555-0008,Palma,true
109,Miguel SÃ¡nchez,miguel@example.com,555-0009,Las Palmas,true
110,Isabel Ruiz,isabel@example.com,555-0010,Alicante,false"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_clientes,
        s3_key="clientes/clientes_activos.csv",
        content_type="text/csv",
        storage_class="INTELLIGENT_TIERING"
    )
    
    # CSV 3: Datos de productos
    print("\n[CSV] Creando CSV de PRODUCTOS...")
    csv_productos = """id,nombre,categoria,precio,stock,proveedor
1001,Laptop Dell XPS,Computadoras,1200.00,15,Dell Inc
1002,Mouse Logitech,PerifÃ©ricos,25.00,100,Logitech
1003,Teclado MecÃ¡nico,PerifÃ©ricos,75.00,45,Keychron
1004,Monitor LG 27,Pantallas,300.00,8,LG
1005,Auriculares Sony,Audio,80.00,60,Sony
1006,Webcam HD,Accesorios,120.00,25,Logitech
1007,SSD Samsung 1TB,Almacenamiento,450.00,20,Samsung
1008,RAM DDR4 16GB,Componentes,100.00,50,Corsair
1009,Procesador Intel,Componentes,550.00,12,Intel
1010,Fuente 750W,Componentes,200.00,18,EVGA"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_productos,
        s3_key="productos/inventario.csv",
        content_type="text/csv",
        storage_class="INTELLIGENT_TIERING"
    )
    
    # CSV 4: Reportes
    print("\n[CSV] Creando CSV de REPORTES...")
    csv_reportes = """mes,ingresos,gastos,ganancia,margen
Enero,15100.00,8500.00,6600.00,0.437
Febrero,18200.00,9100.00,9100.00,0.500
Marzo,21500.00,10200.00,11300.00,0.525
Abril,19800.00,9800.00,10000.00,0.505
Mayo,23100.00,11000.00,12100.00,0.524
Junio,25600.00,12000.00,13600.00,0.531"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_reportes,
        s3_key="reportes/resumen_financiero.csv",
        content_type="text/csv",
        storage_class="INTELLIGENT_TIERING"
    )
    
    # PASO 4: Listar objetos en el bucket
    print("\n\n>>> PASO 4: LISTAR TODOS LOS OBJETOS <<<")
    todos_los_objetos = manager.listar_objetos_s3(bucket_name)
    
    # PASO 5: Listar objetos por carpeta
    print("\n\n>>> PASO 5: LISTAR OBJETOS POR CARPETA <<<")
    
    print("\n[S3] Objetos en carpeta 'ventas':")
    manager.listar_objetos_s3(bucket_name, prefix="ventas/")
    
    print("\n[S3] Objetos en carpeta 'clientes':")
    manager.listar_objetos_s3(bucket_name, prefix="clientes/")
    
    # PASO 6: Obtener contenido de un objeto (sin descargar)
    print("\n\n>>> PASO 6: OBTENER CONTENIDO DE OBJETO (EN MEMORIA) <<<")
    
    print("\n[S3] Obteniendo contenido de 'ventas/ventas_enero_2024.csv'...")
    contenido_ventas = manager.obtener_contenido_s3_como_texto(
        bucket_name=bucket_name,
        s3_key="ventas/ventas_enero_2024.csv"
    )
    
    if contenido_ventas:
        print(f"\n[CONTENIDO] Primeras lÃ­neas del archivo:")
        lineas = contenido_ventas.split("\n")[:5]
        for linea in lineas:
            print(f"  {linea}")
        print(f"  ... ({len(contenido_ventas.split(chr(10)))} filas totales)")
    
    # PASO 7: Descargar objeto a archivo local
    print("\n\n>>> PASO 7: DESCARGAR OBJETO A ARCHIVO LOCAL <<<")
    
    archivo_descargado = manager.descargar_objeto_s3(
        bucket_name=bucket_name,
        s3_key="clientes/clientes_activos.csv",
        file_path="clientes_descargados.csv"
    )
    
    # PASO 8: Obtener informaciÃ³n de objetos especÃ­ficos
    print("\n\n>>> PASO 8: OBTENER INFORMACIÃ“N DE OBJETOS <<<")
    
    objetos_info = {
        "ventas/ventas_enero_2024.csv": "Datos de ventas de enero",
        "clientes/clientes_activos.csv": "Lista de clientes activos",
        "productos/inventario.csv": "Inventario de productos",
        "reportes/resumen_financiero.csv": "Resumen financiero del semestre"
    }
    
    for obj_key, descripcion in objetos_info.items():
        try:
            metadata = manager.s3_client.head_object(
                Bucket=bucket_name,
                Key=obj_key
            )
            tamaÃ±o = metadata["ContentLength"]
            print(f"\n[OBJETO] {obj_key}")
            print(f"  DescripciÃ³n: {descripcion}")
            print(f"  TamaÃ±o: {tamaÃ±o} bytes")
            print(f"  Ãšltima modificaciÃ³n: {metadata['LastModified']}")
        except Exception as e:
            print(f"Error: {str(e)}")
    
    # Guardar info del bucket en archivo de configuraciÃ³n
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    print("\n" + "=" * 80)
    print("âœ“ S3 completado exitosamente")
    print("=" * 80)
    print(f"\nInformaciÃ³n del bucket:")
    print(f"  Nombre: {bucket_name}")
    print(f"  RegiÃ³n: us-east-1")
    print(f"  Objetos creados: {len(todos_los_objetos)}")


# ==================== PROGRAMA S3_GLACIER ====================    

def main_s3_GLACIER():
    """
    MAIN 3: S3 - Crear bucket, carpetas y archivos CSV
    
    Pasos:
    1. Crear bucket S3
    2. Crear carpetas dentro del bucket
    3. Crear archivos CSV con datos
    4. Listar objetos
    5. Descargar/Obtener objetos
    """
    
    print("=" * 80)
    print("PARTE 3: S3 (SIMPLE STORAGE SERVICE)")
    print("=" * 80)
    
    # Crear instancia de manager
    manager = StorageManager(region="us-east-1")
    
    # PASO 1: Crear bucket S3
    print("\n\n>>> PASO 1: CREAR BUCKET S3 <<<")
    bucket_name = "mi-bucket-datos-glacier" + str(int(time.time()))  # Nombre Ãºnico
    
    bucket_creado = manager.crear_bucket_s3(
        bucket_name=bucket_name,
        acl="private",
        encryption=False  # OPCIONAL: EncriptaciÃ³n
    )
    
    if not bucket_creado:
        print("âœ— Error: No se pudo crear el bucket")
        return
    
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    # PASO 2: Crear carpetas en S3
    print("\n\n>>> PASO 2: CREAR CARPETAS EN S3 <<<")
    
    carpetas = ["ventas", "clientes", "productos", "reportes"]
    
    for carpeta in carpetas:
        manager.crear_carpeta_s3(bucket_name, carpeta)
    
    # PASO 3: Crear archivos CSV y subirlos
    print("\n\n>>> PASO 3: CREAR Y SUBIR ARCHIVOS CSV <<<")
    
    # CSV 1: Datos de ventas
    print("\n[CSV] Creando CSV de VENTAS...")
    csv_ventas = """id,fecha,producto,cantidad,precio,total
1,2024-01-01,Laptop,5,1200.00,6000.00
2,2024-01-02,Mouse,50,25.00,1250.00
3,2024-01-03,Teclado,30,75.00,2250.00
4,2024-01-04,Monitor,10,300.00,3000.00
5,2024-01-05,Auriculares,25,80.00,2000.00
6,2024-01-06,Webcam,15,120.00,1800.00
7,2024-01-07,SSD,8,450.00,3600.00
8,2024-01-08,RAM,20,100.00,2000.00
9,2024-01-09,Procesador,5,550.00,2750.00
10,2024-01-10,Fuente,12,200.00,2400.00"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_ventas,
        s3_key="ventas/ventas_enero_2024.csv",  # Ruta con carpeta
        content_type="text/csv",
        storage_class="GLACIER"
    )
    
    # CSV 2: Datos de clientes
    print("\n[CSV] Creando CSV de CLIENTES...")
    csv_clientes = """id,nombre,email,telefono,ciudad,activo
101,Juan GarcÃ­a,juan@example.com,555-0001,Madrid,true
102,MarÃ­a LÃ³pez,maria@example.com,555-0002,Barcelona,true
103,Carlos RodrÃ­guez,carlos@example.com,555-0003,Valencia,false
104,Ana MartÃ­nez,ana@example.com,555-0004,Sevilla,true
105,Luis FernÃ¡ndez,luis@example.com,555-0005,Bilbao,true
106,Elena JimÃ©nez,elena@example.com,555-0006,Malaga,true
107,David PÃ©rez,david@example.com,555-0007,Murcia,false
108,Sofia GÃ³mez,sofia@example.com,555-0008,Palma,true
109,Miguel SÃ¡nchez,miguel@example.com,555-0009,Las Palmas,true
110,Isabel Ruiz,isabel@example.com,555-0010,Alicante,false"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_clientes,
        s3_key="clientes/clientes_activos.csv",
        content_type="text/csv",
        storage_class="GLACIER"
    )
    
    # CSV 3: Datos de productos
    print("\n[CSV] Creando CSV de PRODUCTOS...")
    csv_productos = """id,nombre,categoria,precio,stock,proveedor
1001,Laptop Dell XPS,Computadoras,1200.00,15,Dell Inc
1002,Mouse Logitech,PerifÃ©ricos,25.00,100,Logitech
1003,Teclado MecÃ¡nico,PerifÃ©ricos,75.00,45,Keychron
1004,Monitor LG 27,Pantallas,300.00,8,LG
1005,Auriculares Sony,Audio,80.00,60,Sony
1006,Webcam HD,Accesorios,120.00,25,Logitech
1007,SSD Samsung 1TB,Almacenamiento,450.00,20,Samsung
1008,RAM DDR4 16GB,Componentes,100.00,50,Corsair
1009,Procesador Intel,Componentes,550.00,12,Intel
1010,Fuente 750W,Componentes,200.00,18,EVGA"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_productos,
        s3_key="productos/inventario.csv",
        content_type="text/csv",
        storage_class="GLACIER"
    )
    
    # CSV 4: Reportes
    print("\n[CSV] Creando CSV de REPORTES...")
    csv_reportes = """mes,ingresos,gastos,ganancia,margen
Enero,15100.00,8500.00,6600.00,0.437
Febrero,18200.00,9100.00,9100.00,0.500
Marzo,21500.00,10200.00,11300.00,0.525
Abril,19800.00,9800.00,10000.00,0.505
Mayo,23100.00,11000.00,12100.00,0.524
Junio,25600.00,12000.00,13600.00,0.531"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_reportes,
        s3_key="reportes/resumen_financiero.csv",
        content_type="text/csv",
        storage_class="GLACIER"
    )
    
    # PASO 4: Listar objetos en el bucket
    print("\n\n>>> PASO 4: LISTAR TODOS LOS OBJETOS <<<")
    todos_los_objetos = manager.listar_objetos_s3(bucket_name)
    
    # PASO 5: Listar objetos por carpeta
    print("\n\n>>> PASO 5: LISTAR OBJETOS POR CARPETA <<<")
    
    print("\n[S3] Objetos en carpeta 'ventas':")
    manager.listar_objetos_s3(bucket_name, prefix="ventas/")
    
    print("\n[S3] Objetos en carpeta 'clientes':")
    manager.listar_objetos_s3(bucket_name, prefix="clientes/")
    
    # PASO 6: Obtener contenido de un objeto (sin descargar)
    print("\n\n>>> PASO 6: OBTENER CONTENIDO DE OBJETO (EN MEMORIA) <<<")
    
    print("\n[S3] Obteniendo contenido de 'ventas/ventas_enero_2024.csv'...")
    contenido_ventas = manager.obtener_contenido_s3_como_texto(
        bucket_name=bucket_name,
        s3_key="ventas/ventas_enero_2024.csv"
    )
    
    if contenido_ventas:
        print(f"\n[CONTENIDO] Primeras lÃ­neas del archivo:")
        lineas = contenido_ventas.split("\n")[:5]
        for linea in lineas:
            print(f"  {linea}")
        print(f"  ... ({len(contenido_ventas.split(chr(10)))} filas totales)")
    
    # PASO 7: Descargar objeto a archivo local
    print("\n\n>>> PASO 7: DESCARGAR OBJETO A ARCHIVO LOCAL <<<")
    
    archivo_descargado = manager.descargar_objeto_s3(
        bucket_name=bucket_name,
        s3_key="clientes/clientes_activos.csv",
        file_path="clientes_descargados.csv"
    )
    
    # PASO 8: Obtener informaciÃ³n de objetos especÃ­ficos
    print("\n\n>>> PASO 8: OBTENER INFORMACIÃ“N DE OBJETOS <<<")
    
    objetos_info = {
        "ventas/ventas_enero_2024.csv": "Datos de ventas de enero",
        "clientes/clientes_activos.csv": "Lista de clientes activos",
        "productos/inventario.csv": "Inventario de productos",
        "reportes/resumen_financiero.csv": "Resumen financiero del semestre"
    }
    
    for obj_key, descripcion in objetos_info.items():
        try:
            metadata = manager.s3_client.head_object(
                Bucket=bucket_name,
                Key=obj_key
            )
            tamaÃ±o = metadata["ContentLength"]
            print(f"\n[OBJETO] {obj_key}")
            print(f"  DescripciÃ³n: {descripcion}")
            print(f"  TamaÃ±o: {tamaÃ±o} bytes")
            print(f"  Ãšltima modificaciÃ³n: {metadata['LastModified']}")
        except Exception as e:
            print(f"Error: {str(e)}")
    
    # Guardar info del bucket en archivo de configuraciÃ³n
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    print("\n" + "=" * 80)
    print("âœ“ S3 completado exitosamente")
    print("=" * 80)
    print(f"\nInformaciÃ³n del bucket:")
    print(f"  Nombre: {bucket_name}")
    print(f"  RegiÃ³n: us-east-1")
    print(f"  Objetos creados: {len(todos_los_objetos)}")

     

# ==================== PROGRAMA S3_DEEP_ARCHIVE ====================    

def main_s3_DEEP_ARCHIVE():
    """
    MAIN 3: S3 - Crear bucket, carpetas y archivos CSV
    
    Pasos:
    1. Crear bucket S3
    2. Crear carpetas dentro del bucket
    3. Crear archivos CSV con datos
    4. Listar objetos
    5. Descargar/Obtener objetos
    """
    
    print("=" * 80)
    print("PARTE 3: S3 (SIMPLE STORAGE SERVICE)")
    print("=" * 80)
    
    # Crear instancia de manager
    manager = StorageManager(region="us-east-1")
    
    # PASO 1: Crear bucket S3
    print("\n\n>>> PASO 1: CREAR BUCKET S3 <<<")
    bucket_name = "mi-bucket-datos-deep-archive" + str(int(time.time()))  # Nombre Ãºnico
    
    bucket_creado = manager.crear_bucket_s3(
        bucket_name=bucket_name,
        acl="private",
        encryption=False  # OPCIONAL: EncriptaciÃ³n
    )
    
    if not bucket_creado:
        print("âœ— Error: No se pudo crear el bucket")
        return
    
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    # PASO 2: Crear carpetas en S3
    print("\n\n>>> PASO 2: CREAR CARPETAS EN S3 <<<")
    
    carpetas = ["ventas", "clientes", "productos", "reportes"]
    
    for carpeta in carpetas:
        manager.crear_carpeta_s3(bucket_name, carpeta)
    
    # PASO 3: Crear archivos CSV y subirlos
    print("\n\n>>> PASO 3: CREAR Y SUBIR ARCHIVOS CSV <<<")
    
    # CSV 1: Datos de ventas
    print("\n[CSV] Creando CSV de VENTAS...")
    csv_ventas = """id,fecha,producto,cantidad,precio,total
1,2024-01-01,Laptop,5,1200.00,6000.00
2,2024-01-02,Mouse,50,25.00,1250.00
3,2024-01-03,Teclado,30,75.00,2250.00
4,2024-01-04,Monitor,10,300.00,3000.00
5,2024-01-05,Auriculares,25,80.00,2000.00
6,2024-01-06,Webcam,15,120.00,1800.00
7,2024-01-07,SSD,8,450.00,3600.00
8,2024-01-08,RAM,20,100.00,2000.00
9,2024-01-09,Procesador,5,550.00,2750.00
10,2024-01-10,Fuente,12,200.00,2400.00"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_ventas,
        s3_key="ventas/ventas_enero_2024.csv",  # Ruta con carpeta
        content_type="text/csv",
        storage_class="DEEP_ARCHIVE"
    )
    
    # CSV 2: Datos de clientes
    print("\n[CSV] Creando CSV de CLIENTES...")
    csv_clientes = """id,nombre,email,telefono,ciudad,activo
101,Juan GarcÃ­a,juan@example.com,555-0001,Madrid,true
102,MarÃ­a LÃ³pez,maria@example.com,555-0002,Barcelona,true
103,Carlos RodrÃ­guez,carlos@example.com,555-0003,Valencia,false
104,Ana MartÃ­nez,ana@example.com,555-0004,Sevilla,true
105,Luis FernÃ¡ndez,luis@example.com,555-0005,Bilbao,true
106,Elena JimÃ©nez,elena@example.com,555-0006,Malaga,true
107,David PÃ©rez,david@example.com,555-0007,Murcia,false
108,Sofia GÃ³mez,sofia@example.com,555-0008,Palma,true
109,Miguel SÃ¡nchez,miguel@example.com,555-0009,Las Palmas,true
110,Isabel Ruiz,isabel@example.com,555-0010,Alicante,false"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_clientes,
        s3_key="clientes/clientes_activos.csv",
        content_type="text/csv",
        storage_class="DEEP_ARCHIVE"
    )
    
    # CSV 3: Datos de productos
    print("\n[CSV] Creando CSV de PRODUCTOS...")
    csv_productos = """id,nombre,categoria,precio,stock,proveedor
1001,Laptop Dell XPS,Computadoras,1200.00,15,Dell Inc
1002,Mouse Logitech,PerifÃ©ricos,25.00,100,Logitech
1003,Teclado MecÃ¡nico,PerifÃ©ricos,75.00,45,Keychron
1004,Monitor LG 27,Pantallas,300.00,8,LG
1005,Auriculares Sony,Audio,80.00,60,Sony
1006,Webcam HD,Accesorios,120.00,25,Logitech
1007,SSD Samsung 1TB,Almacenamiento,450.00,20,Samsung
1008,RAM DDR4 16GB,Componentes,100.00,50,Corsair
1009,Procesador Intel,Componentes,550.00,12,Intel
1010,Fuente 750W,Componentes,200.00,18,EVGA"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_productos,
        s3_key="productos/inventario.csv",
        content_type="text/csv",
        storage_class="DEEP_ARCHIVE"
    )
    
    # CSV 4: Reportes
    print("\n[CSV] Creando CSV de REPORTES...")
    csv_reportes = """mes,ingresos,gastos,ganancia,margen
Enero,15100.00,8500.00,6600.00,0.437
Febrero,18200.00,9100.00,9100.00,0.500
Marzo,21500.00,10200.00,11300.00,0.525
Abril,19800.00,9800.00,10000.00,0.505
Mayo,23100.00,11000.00,12100.00,0.524
Junio,25600.00,12000.00,13600.00,0.531"""
    
    manager.subir_contenido_s3_con_storage_class(
        bucket_name=bucket_name,
        contenido=csv_reportes,
        s3_key="reportes/resumen_financiero.csv",
        content_type="text/csv",
        storage_class="DEEP_ARCHIVE"
    )
    
    # PASO 4: Listar objetos en el bucket
    print("\n\n>>> PASO 4: LISTAR TODOS LOS OBJETOS <<<")
    todos_los_objetos = manager.listar_objetos_s3(bucket_name)
    
    # PASO 5: Listar objetos por carpeta
    print("\n\n>>> PASO 5: LISTAR OBJETOS POR CARPETA <<<")
    
    print("\n[S3] Objetos en carpeta 'ventas':")
    manager.listar_objetos_s3(bucket_name, prefix="ventas/")
    
    print("\n[S3] Objetos en carpeta 'clientes':")
    manager.listar_objetos_s3(bucket_name, prefix="clientes/")
    
    # PASO 6: Obtener contenido de un objeto (sin descargar)
    print("\n\n>>> PASO 6: OBTENER CONTENIDO DE OBJETO (EN MEMORIA) <<<")
    
    print("\n[S3] Obteniendo contenido de 'ventas/ventas_enero_2024.csv'...")
    contenido_ventas = manager.obtener_contenido_s3_como_texto(
        bucket_name=bucket_name,
        s3_key="ventas/ventas_enero_2024.csv"
    )
    
    if contenido_ventas:
        print(f"\n[CONTENIDO] Primeras lÃ­neas del archivo:")
        lineas = contenido_ventas.split("\n")[:5]
        for linea in lineas:
            print(f"  {linea}")
        print(f"  ... ({len(contenido_ventas.split(chr(10)))} filas totales)")
    
    # PASO 7: Descargar objeto a archivo local
    print("\n\n>>> PASO 7: DESCARGAR OBJETO A ARCHIVO LOCAL <<<")
    
    archivo_descargado = manager.descargar_objeto_s3(
        bucket_name=bucket_name,
        s3_key="clientes/clientes_activos.csv",
        file_path="clientes_descargados.csv"
    )
    
    # PASO 8: Obtener informaciÃ³n de objetos especÃ­ficos
    print("\n\n>>> PASO 8: OBTENER INFORMACIÃ“N DE OBJETOS <<<")
    
    objetos_info = {
        "ventas/ventas_enero_2024.csv": "Datos de ventas de enero",
        "clientes/clientes_activos.csv": "Lista de clientes activos",
        "productos/inventario.csv": "Inventario de productos",
        "reportes/resumen_financiero.csv": "Resumen financiero del semestre"
    }
    
    for obj_key, descripcion in objetos_info.items():
        try:
            metadata = manager.s3_client.head_object(
                Bucket=bucket_name,
                Key=obj_key
            )
            tamaÃ±o = metadata["ContentLength"]
            print(f"\n[OBJETO] {obj_key}")
            print(f"  DescripciÃ³n: {descripcion}")
            print(f"  TamaÃ±o: {tamaÃ±o} bytes")
            print(f"  Ãšltima modificaciÃ³n: {metadata['LastModified']}")
        except Exception as e:
            print(f"Error: {str(e)}")
    
    # Guardar info del bucket en archivo de configuraciÃ³n
    ConfigManager.actualizar("s3_bucket", bucket_name)
    
    print("\n" + "=" * 80)
    print("âœ“ S3 completado exitosamente")
    print("=" * 80)
    print(f"\nInformaciÃ³n del bucket:")
    print(f"  Nombre: {bucket_name}")
    print(f"  RegiÃ³n: us-east-1")
    print(f"  Objetos creados: {len(todos_los_objetos)}")

   

# ==================== PROGRAMA PRINCIPAL ====================

def main_selector():
    """
    Selector interactivo para ejecutar los mains
    """
    while True:
        print("\n" + "=" * 80)
        print("SELECTOR DE PARTES - ALMACENAMIENTO AWS")
        print("=" * 80)
        print("\n1. Crear Infraestructura (VPC, SG, Subnet, KeyPair)")
        print("2. EC2, EBS, EFS")
        print("3. S3_STANDART")
        print("4. S3_STANDARD_IA")
        print("5. S3_INTELLIGENT_TIERING")
        print("6. S3_GLACIER")
        print("7. S3_DEEP_ARCHIVE")
        print("8. Ver configuraciÃ³n guardada (aws_config.json)")
        print("9. Ejecutar todas las partes en orden")
        print("10. Limpiar configuraciÃ³n")
        print("0. Salir")
        
        opcion = input("\nSelecciona una opciÃ³n (0-6): ").strip()
        
        if opcion == "1":
            main_security_group_subnet_keypairs()
        elif opcion == "2":
            main_ec2_efs_ebs()
        elif opcion == "3":
            main_s3_STANDARD()
        elif opcion == "4":
            main_s3_STANDARD_IA()
        elif opcion == "5":
            main_s3_INTELLIGENT_TIERING()
        elif opcion == "6":
            main_s3_GLACIER()
        elif opcion == "7":
            main_s3_DEEP_ARCHIVE()
        elif opcion == "8":
            ConfigManager.mostrar()
        elif opcion == "9":
            print("\nEjecutando todas las partes en orden...\n")
            main_security_group_subnet_keypairs()
            print("\n" + "=" * 80)
            print("Infraestructura creada. Presiona ENTER para continuar...")
            input()
            
            main_ec2_efs_ebs()
            print("\n" + "=" * 80)
            print("EC2, EBS y EFS creados. Presiona ENTER para continuar...")
            input()
            
            main_s3_STANDARD()
            print("\n" + "=" * 80)
            print("S3 STANDARD creado. Todas las partes completadas.")

            main_s3_STANDARD_IA()
            print("\n" + "=" * 80)
            print("S3 STANDARD IA creado. Todas las partes completadas.")

            main_s3_INTELLIGENT_TIERING()
            print("\n" + "=" * 80)
            print("S3 INTELLIGENT TIERING creado. Todas las partes completadas.")

            main_s3_GLACIER()
            print("\n" + "=" * 80)
            print("S3 GLACIER creado. Todas las partes completadas.")

            main_s3_DEEP_ARCHIVE()
            print("\n" + "=" * 80)
            print("S3 DEEP ARCHIVE creado. Todas las partes completadas.")
        elif opcion == "10":
            confirmacion = input("\nÂ¿EstÃ¡s seguro de que deseas limpiar la configuraciÃ³n? (s/n): ").strip().lower()
            if confirmacion == "s":
                ConfigManager.limpiar()
            else:
                print("OperaciÃ³n cancelada")
        elif opcion == "0":
            print("Saliendo...")
            break
        else:
            print("âœ— OpciÃ³n no vÃ¡lida")


if __name__ == '__main__':
    main_selector()

